# -*- coding: utf-8 -*-
"""Copy of config.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MoUgqpK-a4UAUz7SGWvAmwXI-x45Fpl_
"""

import torch
import albumentations as A
from albumentations.pytorch import ToTensorV2

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
TRAIN_DIR = "/content/grive/MyDrive/Colab Notebooks/ECE_50024_Machine_Learning/CycleGAN_Final_Project/data/train"
VAL_DIR = "/content/grive/MyDrive/Colab Notebooks/ECE_50024_Machine_Learning/CycleGAN_Final_Project/data/val"
BATCH_SIZE = 1 # Specified per paper
LEARNING_RATE = 0.0002 # Specified per paper
LAMBDA_CYCLE = 10 # Specified per paper
LAMBDA_IDENTITY = 0.5 * LAMBDA_CYCLE # decided to use identity loss of my dataset and project to see if reults improve. Paper set it to 0.5*LAMBDA_CYCLE
NUM_WORKERS = 4 # Specified per paper's code'
NUM_EPOCHS = 100 # Paper had 200 epochs total. Reduced epochs to 100 to reduce runtime
LOAD_MODEL = False
SAVE_MODEL = True
CHECKPOINT_GEN_X = "genx.pth.tar" # Checkpoint for generator X
CHECKPOINT_GEN_Y = "geny.pth.tar" # Checkpoint for generator Y
CHECKPOINT_DISCRIMINATOR_X = "discriminatorx.pth.tar" # Checkpoint for discriminator X
CHECKPOINT_DISCRIMINATOR_Y = "discriminatory.pth.tar" # Checkpoint for discriminator Y

transforms = A.Compose(
    [
      A.Resize(width=256, height=256), 
      A.HorizontalFlip(p=0.5),
      A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255),
      ToTensorV2(),
    ],
    additional_targets={"image0": "image"},
)